{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import Tox\n",
    "import deepchem\n",
    "import xgboost\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "from rdkit.Chem.EState import EState\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "\n",
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 5821/5821 [00:02<00:00, 2283.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.874117\n",
      "Step 2000 validation: roc_auc_score=0.865843\n",
      "Step 3000 validation: roc_auc_score=0.85053\n",
      "Step 4000 validation: roc_auc_score=0.823223\n",
      "Step 5000 validation: roc_auc_score=0.821407\n",
      "1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "1457\n",
      "predictions for run #\n",
      "1\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5821/5821 [00:01<00:00, 3480.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.795735\n",
      "Step 2000 validation: roc_auc_score=0.790728\n",
      "Step 3000 validation: roc_auc_score=0.799542\n",
      "Step 4000 validation: roc_auc_score=0.785934\n",
      "1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "1457\n",
      "predictions for run #\n",
      "2\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5821/5821 [00:01<00:00, 3218.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.859539\n",
      "Step 2000 validation: roc_auc_score=0.822343\n",
      "Step 3000 validation: roc_auc_score=0.83282\n",
      "Step 4000 validation: roc_auc_score=0.838085\n",
      "Step 5000 validation: roc_auc_score=0.863053\n",
      "1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "1457\n",
      "predictions for run #\n",
      "3\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5821/5821 [00:01<00:00, 3730.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.859446\n",
      "Step 2000 validation: roc_auc_score=0.841365\n",
      "Step 3000 validation: roc_auc_score=0.840198\n",
      "Step 4000 validation: roc_auc_score=0.838345\n",
      "Step 5000 validation: roc_auc_score=0.833481\n",
      "1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "1457\n",
      "predictions for run #\n",
      "4\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5821/5821 [00:01<00:00, 3708.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5072 calls to <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x00000280044208B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Step 1000 validation: roc_auc_score=0.866028\n",
      "Step 2000 validation: roc_auc_score=0.865939\n",
      "Step 3000 validation: roc_auc_score=0.873723\n",
      "Step 4000 validation: roc_auc_score=0.840261\n",
      "Step 5000 validation: roc_auc_score=0.851494\n",
      "1457\n",
      "1457\n",
      "1457\n",
      "predictions for run #\n",
      "5\n",
      "[1. 1. 1. 1. 1.]\n",
      "Prediction List:\n",
      "[{'ames': array([1., 1., 1., ..., 0., 1., 1.])}, {'ames': array([1., 1., 1., ..., 0., 1., 1.])}, {'ames': array([1., 1., 1., ..., 0., 1., 1.])}, {'ames': array([1., 1., 1., ..., 0., 1., 1.])}, {'ames': array([1., 1., 1., ..., 0., 1., 1.])}]\n"
     ]
    }
   ],
   "source": [
    "predictions_list = []\n",
    "metric = deepchem.deepchem.metrics.Metric(deepchem.deepchem.metrics.roc_auc_score)\n",
    "ecfpFeat = deepchem.deepchem.feat.CircularFingerprint(radius=4)\n",
    "convMolFeat = deepchem.deepchem.feat.ConvMolFeaturizer()\n",
    "xgb_reg_ecfp = xgboost.XGBClassifier()\n",
    "xgb_reg_estate = xgboost.XGBClassifier()\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('ames') \n",
    "    \n",
    "    predictions = {}\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)  \n",
    "\n",
    "    #trainMol = train.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    #validMol = valid.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    testMol = test.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    train_valMol = train_val.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost\n",
    "    #trainFeat = np.stack(np.array(trainMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    #validFeat = np.stack(np.array(validMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    testFeat = np.stack(np.array(testMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    train_valFeat = np.stack(np.array(train_valMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost\n",
    "    #ecfp_f_train = ecfpFeat.featurize(train.iloc[:,1].to_list())\n",
    "    #ecfp_f_valid = ecfpFeat.featurize(valid.iloc[:,1].to_list())\n",
    "    ecfp_f_test = ecfpFeat.featurize(test.iloc[:,1].to_list())\n",
    "    train_val_f = ecfpFeat.featurize(train_val.iloc[:,1].to_list())\n",
    "\n",
    "    #featurize training, valid, and test data for the GCN\n",
    "    cv_f_train = convMolFeat.featurize(train.iloc[:,1].to_list())\n",
    "    cv_f_valid = convMolFeat.featurize(valid.iloc[:,1].to_list())\n",
    "    cv_f_test = convMolFeat.featurize(test.iloc[:,1].to_list())\n",
    "\n",
    "    #convert training and validation data into a deepchem dataset for the gcn\n",
    "    gcn_train_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_train, y=np.array(train.iloc[:,2]), ids=np.array(train.iloc[:,1].to_list()))\n",
    "    gcn_valid_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_valid, y=np.array(valid.iloc[:,2]), ids=np.array(valid.iloc[:,1].to_list()))\n",
    "    gcn_test_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_test, y=np.array(test.iloc[:,2]), ids=np.array(test.iloc[:,1].to_list()))\n",
    "\n",
    "    #fit data on GCN\n",
    "    reg = deepchem.deepchem.models.GraphConvModel(\n",
    "        n_tasks=1, \n",
    "        dropout=.0005,\n",
    "        dense_layer_size=1063,\n",
    "        graph_conv_layers=[128, 128, 128],\n",
    "        mode=\"classification\",)\n",
    "    callback = deepchem.deepchem.models.ValidationCallback(gcn_valid_data, 1000, metric)\n",
    "    reg.fit(gcn_train_data, nb_epoch=100, callbacks=callback)\n",
    "\n",
    "    gcn_pred = reg.predict(dataset=gcn_test_data)\n",
    "    gcn_pred_processed = []\n",
    "    for prediction in gcn_pred:\n",
    "        gcn_pred_processed.append(prediction[0][1])\n",
    "\n",
    "    #fit xgboost model and store np ndarray in xgb_pred\n",
    "    xgb_reg_estate.fit(X=train_valFeat, y=train_val.iloc[:,2], eval_metric=\"auc\", verbose=True)\n",
    "    xgb_reg_ecfp.fit(X=train_val_f, y=train_val.iloc[:,2], eval_metric=\"auc\")\n",
    "    pred_estate = xgb_reg_estate.predict(X=testFeat)\n",
    "    pred_ecfp = xgb_reg_ecfp.predict(X=ecfp_f_test)\n",
    "\n",
    "    # store test predictions in y_pred_test\n",
    "    y_pred_test = np.round(np.mean([ pred_estate, pred_ecfp, gcn_pred_processed ], axis=0))\n",
    "\n",
    "    print(\"predictions for run #\")\n",
    "    print(seed)\n",
    "    print(y_pred_test[0:5])\n",
    "        \n",
    "    predictions[name] = y_pred_test\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "print(\"Prediction List:\")\n",
    "print(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ames': {'roc-auc': 0.766}}\n",
      "{'ames': {'roc-auc': 0.781}}\n",
      "{'ames': {'roc-auc': 0.77}}\n",
      "{'ames': {'roc-auc': 0.775}}\n",
      "{'ames': {'roc-auc': 0.775}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ames': [0.773, 0.005]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in predictions_list:\n",
    "    print(group.evaluate(i))\n",
    "\n",
    "group.evaluate_many(predictions_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d9ef161e060c37aa994177a4d833cab797e22621213b4f88b9fe284585c74c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deepchem-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
