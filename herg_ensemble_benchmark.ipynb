{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import Tox\n",
    "import deepchem\n",
    "import xgboost\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "from rdkit.Chem.EState import EState\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "\n",
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 523/523 [00:00<00:00, 1473.10it/s]\n",
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for run #\n",
      "1\n",
      "[0.99982685, 0.96124256, 0.9999019, 0.999772, 0.99981743]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [00:00<00:00, 1291.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6736/2514007421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         mode=\"classification\",)\n\u001b[0;32m     50\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValidationCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgcn_valid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgcn_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mgcn_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgcn_test_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\deepchem\\models\\keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m    \"\"\"\n\u001b[1;32m--> 355\u001b[1;33m     return self.fit_generator(\n\u001b[0m\u001b[0;32m    356\u001b[0m         self.default_generator(\n\u001b[0;32m    357\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\deepchem\\models\\keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m       \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_gradient_for_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m       \u001b[0mcurrent_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_list = []\n",
    "metric = deepchem.deepchem.metrics.Metric(deepchem.deepchem.metrics.roc_auc_score)\n",
    "ecfpFeat = deepchem.deepchem.feat.CircularFingerprint(radius=4)\n",
    "convMolFeat = deepchem.deepchem.feat.ConvMolFeaturizer()\n",
    "xgb_reg_ecfp = xgboost.XGBClassifier()\n",
    "xgb_reg_estate = xgboost.XGBClassifier()\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('herg') \n",
    "    \n",
    "    predictions = {}\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)  \n",
    "\n",
    "    #trainMol = train.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    #validMol = valid.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    testMol = test.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    train_valMol = train_val.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost\n",
    "    #trainFeat = np.stack(np.array(trainMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    #validFeat = np.stack(np.array(validMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    testFeat = np.stack(np.array(testMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    train_valFeat = np.stack(np.array(train_valMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost\n",
    "    #ecfp_f_train = ecfpFeat.featurize(train.iloc[:,1].to_list())\n",
    "    #ecfp_f_valid = ecfpFeat.featurize(valid.iloc[:,1].to_list())\n",
    "    ecfp_f_test = ecfpFeat.featurize(test.iloc[:,1].to_list())\n",
    "    train_val_f = ecfpFeat.featurize(train_val.iloc[:,1].to_list())\n",
    "\n",
    "    #featurize training, valid, and test data for the GCN\n",
    "    cv_f_train = convMolFeat.featurize(train.iloc[:,1].to_list())\n",
    "    cv_f_valid = convMolFeat.featurize(valid.iloc[:,1].to_list())\n",
    "    cv_f_test = convMolFeat.featurize(test.iloc[:,1].to_list())\n",
    "\n",
    "    #convert training and validation data into a deepchem dataset for the gcn\n",
    "    gcn_train_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_train, y=np.array(train.iloc[:,2]), ids=np.array(train.iloc[:,1].to_list()))\n",
    "    gcn_valid_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_valid, y=np.array(valid.iloc[:,2]), ids=np.array(valid.iloc[:,1].to_list()))\n",
    "    gcn_test_data = deepchem.deepchem.data.NumpyDataset(X=cv_f_test, y=np.array(test.iloc[:,2]), ids=np.array(test.iloc[:,1].to_list()))\n",
    "\n",
    "    #fit data on GCN\n",
    "    reg = deepchem.deepchem.models.GraphConvModel(\n",
    "        n_tasks=1, \n",
    "        dropout=.001,\n",
    "        dense_layer_size=1577,\n",
    "        graph_conv_layers=[128, 128],\n",
    "        mode=\"classification\",)\n",
    "    callback = deepchem.deepchem.models.ValidationCallback(gcn_valid_data, 1000, metric)\n",
    "    reg.fit(gcn_train_data, nb_epoch=100, callbacks=callback)\n",
    "\n",
    "    gcn_pred = reg.predict(dataset=gcn_test_data)\n",
    "    gcn_pred_processed = []\n",
    "    for prediction in gcn_pred:\n",
    "        gcn_pred_processed.append(prediction[0][1])\n",
    "\n",
    "    #fit xgboost model and store np ndarray in xgb_pred\n",
    "    xgb_reg_estate.fit(X=train_valFeat, y=train_val.iloc[:,2], eval_metric=\"auc\", verbose=True)\n",
    "    xgb_reg_ecfp.fit(X=train_val_f, y=train_val.iloc[:,2], eval_metric=\"auc\")\n",
    "    pred_estate = xgb_reg_estate.predict(X=testFeat)\n",
    "    pred_ecfp = xgb_reg_ecfp.predict(X=ecfp_f_test)\n",
    "\n",
    "    # store test predictions in y_pred_test\n",
    "    y_pred_test = gcn_pred_processed #np.round(np.mean([ pred_estate, pred_ecfp, gcn_pred_processed ], axis=0))\n",
    "\n",
    "    print(\"predictions for run #\")\n",
    "    print(seed)\n",
    "    print(y_pred_test[0:5])\n",
    "        \n",
    "    predictions[name] = y_pred_test\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "print(\"Prediction List:\")\n",
    "print(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'herg': {'roc-auc': 0.78}}\n",
      "{'herg': {'roc-auc': 0.739}}\n",
      "{'herg': {'roc-auc': 0.732}}\n",
      "{'herg': {'roc-auc': 0.765}}\n",
      "{'herg': {'roc-auc': 0.785}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'herg': [0.76, 0.021]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in predictions_list:\n",
    "    print(group.evaluate(i))\n",
    "\n",
    "group.evaluate_many(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "WARNING:tensorflow:5 out of the last 52 calls to <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x000001EF576FECA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "init   \t [7.19693503e-02 1.07500000e+03]. \t  0.7037037037037037 \t 0.7853751187084521\n",
      "init   \t [2.54595299e-02 9.08000000e+02]. \t  0.6467236467236468 \t 0.7853751187084521\n",
      "init   \t [1.48644776e-02 1.57800000e+03]. \t  0.7853751187084521 \t 0.7853751187084521\n",
      "1      \t [3.38025562e-02 1.08199998e+03]. \t  0.6999050332383665 \t 0.7853751187084521\n",
      "2      \t [4.16307587e-02 1.08107584e+03]. \t  0.741690408357075 \t 0.7853751187084521\n",
      "3      \t [1.00000000e-03 1.57719365e+03]. \t  \u001b[92m0.8499525166191833\u001b[0m \t 0.8499525166191833\n",
      "4      \t [2.50888308e-02 9.09034410e+02]. \t  0.7977207977207978 \t 0.8499525166191833\n",
      "5      \t [1.00000000e-01 1.57631682e+03]. \t  0.6514719848053181 \t 0.8499525166191833\n",
      "6      \t [1.0000000e-03 1.5790104e+03]. \t  0.698005698005698 \t 0.8499525166191833\n",
      "7      \t [1.00000000e-01 1.58010086e+03]. \t  0.717948717948718 \t 0.8499525166191833\n",
      "8      \t [3.001974e-02 1.094000e+03]. \t  0.758784425451092 \t 0.8499525166191833\n",
      "9      \t [8.12704802e-02 1.09312055e+03]. \t  0.7312440645773979 \t 0.8499525166191833\n",
      "10     \t [2.48520545e-02 9.09951185e+02]. \t  0.7037037037037037 \t 0.8499525166191833\n",
      "11     \t [1.62296569e-02 9.20000000e+02]. \t  0.7369420702754036 \t 0.8499525166191833\n",
      "12     \t [1.00000000e-01 1.09501318e+03]. \t  0.7141500474833808 \t 0.8499525166191833\n",
      "13     \t [9.02843873e-03 8.98000000e+02]. \t  0.7492877492877492 \t 0.8499525166191833\n",
      "14     \t [3.57934068e-03 8.98893487e+02]. \t  0.7958214624881292 \t 0.8499525166191833\n",
      "15     \t [1.00000000e-01 9.11067353e+02]. \t  0.7293447293447294 \t 0.8499525166191833\n",
      "16     \t [7.64945173e-02 1.07595726e+03]. \t  0.7321937321937322 \t 0.8499525166191833\n",
      "17     \t [1.00000000e-03 1.07701655e+03]. \t  0.7378917378917379 \t 0.8499525166191833\n",
      "18     \t [4.79294807e-02 9.19090585e+02]. \t  0.8233618233618234 \t 0.8499525166191833\n",
      "19     \t [1.00000000e-03 9.12070841e+02]. \t  0.7730294396961064 \t 0.8499525166191833\n",
      "20     \t [1.00000000e-03 1.58112686e+03]. \t  0.658119658119658 \t 0.8499525166191833\n"
     ]
    }
   ],
   "source": [
    "def model_builder(**model_params):\n",
    "  return deepchem.deepchem.models.GraphConvModel(n_tasks=1, mode=\"classification\", graph_conv_layers=[128, 128])\n",
    "\n",
    "optimizer = deepchem.deepchem.hyper.GaussianProcessHyperparamOpt(model_builder)\n",
    "\n",
    "params_dict = {\"dropout\": .01, \"dense_layer_size\": 200}\n",
    "\n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, gcn_train_data, gcn_valid_data, metric, search_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.001, 'dense_layer_size': 1577}\n",
      "{'_dense_layer_size_1075_dropout_0.071969': 0.7037037037037037, '_dense_layer_size_908_dropout_0.025460': 0.6467236467236468, '_dense_layer_size_1578_dropout_0.014864': 0.7853751187084521, '_dense_layer_size_1081_dropout_0.033803': 0.6999050332383665, '_dense_layer_size_1081_dropout_0.041631': 0.741690408357075, '_dense_layer_size_1577_dropout_0.001000': 0.8499525166191833, '_dense_layer_size_909_dropout_0.025089': 0.7977207977207978, '_dense_layer_size_1576_dropout_0.100000': 0.6514719848053181, '_dense_layer_size_1579_dropout_0.001000': 0.698005698005698, '_dense_layer_size_1580_dropout_0.100000': 0.717948717948718, '_dense_layer_size_1094_dropout_0.030020': 0.758784425451092, '_dense_layer_size_1093_dropout_0.081270': 0.7312440645773979, '_dense_layer_size_909_dropout_0.024852': 0.7037037037037037, '_dense_layer_size_920_dropout_0.016230': 0.7369420702754036, '_dense_layer_size_1095_dropout_0.100000': 0.7141500474833808, '_dense_layer_size_898_dropout_0.009028': 0.7492877492877492, '_dense_layer_size_898_dropout_0.003579': 0.7958214624881292, '_dense_layer_size_911_dropout_0.100000': 0.7293447293447294, '_dense_layer_size_1075_dropout_0.076495': 0.7321937321937322, '_dense_layer_size_1077_dropout_0.001000': 0.7378917378917379, '_dense_layer_size_919_dropout_0.047929': 0.8233618233618234, '_dense_layer_size_912_dropout_0.001000': 0.7730294396961064, '_dense_layer_size_1581_dropout_0.001000': 0.658119658119658}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparams)\n",
    "print(all_results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d9ef161e060c37aa994177a4d833cab797e22621213b4f88b9fe284585c74c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deepchem-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
