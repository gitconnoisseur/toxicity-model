{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "import deepchem\n",
    "import xgboost\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prauc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 1989.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:07] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:08] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:09] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:09] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:09] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:11] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:11] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:12] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:12] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:11:13] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.00541384]. \t  0.35007340725398467 \t 0.35007340725398467\n",
      "init   \t [0.00593266]. \t  0.2745904384277409 \t 0.35007340725398467\n",
      "init   \t [0.01777219]. \t  0.34244474420464843 \t 0.35007340725398467\n",
      "1      \t [0.02]. \t  0.3471708364054967 \t 0.35007340725398467\n",
      "2      \t [0.01999897]. \t  \u001b[92m0.38800721411014416\u001b[0m \t 0.38800721411014416\n",
      "3      \t [0.01985563]. \t  0.35704510212806195 \t 0.38800721411014416\n",
      "4      \t [0.01995619]. \t  \u001b[92m0.4296178355406276\u001b[0m \t 0.4296178355406276\n",
      "5      \t [0.01974793]. \t  0.4204952291991251 \t 0.4296178355406276\n",
      "6      \t [0.01998635]. \t  0.4232710593341549 \t 0.4296178355406276\n",
      "7      \t [0.01992823]. \t  0.25788765742703734 \t 0.4296178355406276\n",
      "8      \t [0.00663331]. \t  \u001b[92m0.43650243408127687\u001b[0m \t 0.43650243408127687\n",
      "9      \t [0.01819273]. \t  \u001b[92m0.4688863361560107\u001b[0m \t 0.4688863361560107\n",
      "10     \t [0.01908381]. \t  0.40019361268101894 \t 0.4688863361560107\n",
      "11     \t [0.01829961]. \t  0.3981844824628311 \t 0.4688863361560107\n",
      "12     \t [0.00858265]. \t  0.30962019362333193 \t 0.4688863361560107\n",
      "13     \t [0.00965808]. \t  0.40904215104979347 \t 0.4688863361560107\n",
      "14     \t [0.01480546]. \t  0.3965238992730828 \t 0.4688863361560107\n",
      "15     \t [0.00895055]. \t  0.3974138618821397 \t 0.4688863361560107\n",
      "16     \t [0.00532041]. \t  0.4685953008910435 \t 0.4688863361560107\n",
      "17     \t [0.00586224]. \t  0.32389732035786634 \t 0.4688863361560107\n",
      "18     \t [0.00628715]. \t  0.29200223977152323 \t 0.4688863361560107\n",
      "19     \t [0.01178755]. \t  0.2848051961676106 \t 0.4688863361560107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20     \t [0.01426449]. \t  0.3822112147841674 \t 0.4688863361560107\n",
      "cyp2d6_substrate_carbonmangels\n",
      "{'estate': {'max_depth': 3}, 'ecfp': {'max_depth': 3}, 'gcn': {'dropout': 0.018192731791502863}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 2268.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:28:08] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:28:09] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07110067, 0.14426295, 0.99748945, 0.8868608, 1.3199063e-05]\n",
      "[0 0 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "predictions for run #\n",
      "1\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 1560.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:41] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:33:41] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028676355, 0.061676733, 0.98857343, 0.1986119, 3.3721495e-05]\n",
      "[0 0 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "predictions for run #\n",
      "2\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 2154.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:58] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:38:58] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0017059555, 0.0038826838, 0.9785346, 0.17107305, 3.4639474e-05]\n",
      "[0 0 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "predictions for run #\n",
      "3\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 2029.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:42:13] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:42:13] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0209422e-05, 0.29144293, 0.99453896, 0.0035255149, 0.00039450568]\n",
      "[0 0 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "predictions for run #\n",
      "4\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532/532 [00:00<00:00, 2211.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:04] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:04] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008490027, 0.008420575, 0.9762548, 0.28174946, 6.6656365e-05]\n",
      "[0 0 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "predictions for run #\n",
      "5\n",
      "[0. 0. 0. 0. 0.]\n",
      "[{'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}]\n",
      "{'cyp2d6_substrate_carbonmangels': [0.48, 0.019]}\n",
      "rocauc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 1862.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:09] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:10] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:11] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:11] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:12] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:12] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:13] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:14] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:15] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:15] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:16] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:17] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:45:18] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.01105178]. \t  0.7703081232492996 \t 0.8263305322128851\n",
      "init   \t [0.01788708]. \t  0.8263305322128851 \t 0.8263305322128851\n",
      "init   \t [0.00851757]. \t  0.7535014005602241 \t 0.8263305322128851\n",
      "1      \t [0.02]. \t  \u001b[92m0.8711484593837535\u001b[0m \t 0.8711484593837535\n",
      "2      \t [0.01995476]. \t  0.8319327731092437 \t 0.8711484593837535\n",
      "3      \t [0.01980385]. \t  \u001b[92m0.876750700280112\u001b[0m \t 0.876750700280112\n",
      "4      \t [0.01998524]. \t  0.7114845938375349 \t 0.876750700280112\n",
      "5      \t [0.01988386]. \t  \u001b[92m0.9019607843137255\u001b[0m \t 0.9019607843137255\n",
      "6      \t [0.00540271]. \t  0.8627450980392157 \t 0.9019607843137255\n",
      "7      \t [0.01430838]. \t  0.865546218487395 \t 0.9019607843137255\n",
      "8      \t [0.00749036]. \t  0.8711484593837534 \t 0.9019607843137255\n",
      "9      \t [0.00513126]. \t  0.7478991596638656 \t 0.9019607843137255\n",
      "10     \t [0.01145409]. \t  0.7198879551820728 \t 0.9019607843137255\n",
      "11     \t [0.01243986]. \t  0.7983193277310924 \t 0.9019607843137255\n",
      "12     \t [0.01894719]. \t  0.8067226890756303 \t 0.9019607843137255\n",
      "13     \t [0.01147384]. \t  \u001b[92m0.9159663865546218\u001b[0m \t 0.9159663865546218\n",
      "14     \t [0.0076755]. \t  0.7450980392156863 \t 0.9159663865546218\n",
      "15     \t [0.01814917]. \t  0.7871148459383752 \t 0.9159663865546218\n",
      "16     \t [0.01015868]. \t  0.7731092436974789 \t 0.9159663865546218\n",
      "17     \t [0.01940577]. \t  0.8123249299719888 \t 0.9159663865546218\n",
      "18     \t [0.01562343]. \t  \u001b[92m0.927170868347339\u001b[0m \t 0.927170868347339\n",
      "19     \t [0.01415671]. \t  0.8739495798319328 \t 0.927170868347339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20     \t [0.01951807]. \t  0.8599439775910365 \t 0.927170868347339\n",
      "hia_hou\n",
      "{'estate': {'max_depth': 3}, 'ecfp': {'max_depth': 3}, 'gcn': {'dropout': 0.015623428168410156}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 1247.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:00:21] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:21] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999988, 0.99999046, 0.99987996, 0.99979776, 0.9998683]\n",
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "predictions for run #\n",
      "1\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 2275.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:05:05] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:05:05] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999994, 0.9999896, 0.99998224, 0.99998426, 0.9999647]\n",
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "predictions for run #\n",
      "2\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 2041.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:42] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:42] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999989, 0.9999683, 0.9999975, 0.9999734, 0.9998392]\n",
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "predictions for run #\n",
      "3\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 2336.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:21] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:21] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9999995, 0.9999989, 0.9999943, 0.9999932]\n",
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "predictions for run #\n",
      "4\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:00<00:00, 2516.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:13:25] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:25] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.99999964, 0.9999949, 0.9999981, 0.9999949, 0.9998455]\n",
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "predictions for run #\n",
      "5\n",
      "[1. 1. 1. 1. 1.]\n",
      "[{'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}, {'cyp2d6_substrate_carbonmangels': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])}, {'hia_hou': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}, {'hia_hou': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}, {'hia_hou': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}, {'hia_hou': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}, {'hia_hou': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cyp2d6_substrate_carbonmangels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23784/1248916883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deepchem-test\\lib\\site-packages\\tdc\\benchmark_group\\base_group.py\u001b[0m in \u001b[0;36mevaluate_many\u001b[1;34m(self, preds, save_file_name, results_individual)\u001b[0m\n\u001b[0;32m    223\u001b[0m                         \u001b[0mmy_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mindividual_result\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindividual_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                                 \u001b[0mmy_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindividual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                                 \u001b[0mmy_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cyp2d6_substrate_carbonmangels'"
     ]
    }
   ],
   "source": [
    "rocAucMetric = deepchem.deepchem.metrics.Metric(deepchem.deepchem.metrics.roc_auc_score)\n",
    "ecfpFeat = deepchem.deepchem.feat.CircularFingerprint(radius=4)\n",
    "convMolFeat = deepchem.deepchem.feat.ConvMolFeaturizer()\n",
    "xgb_reg_ecfp = xgboost.XGBClassifier()\n",
    "xgb_reg_estate = xgboost.XGBClassifier()\n",
    "praucMetric = deepchem.deepchem.metrics.prc_auc_score\n",
    "praucMetricWrapped = deepchem.deepchem.metrics.Metric(deepchem.deepchem.metrics.prc_auc_score)\n",
    "\n",
    "\"\"\"params = {'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\"\"\"\n",
    "\n",
    "params = {\"max_depth\": [3, 4]}\n",
    "\n",
    "classificationDatasets = ['HIA_Hou', 'Pgp_Broccatelli', 'Bioavailability_Ma', 'BBB_Martins', 'CYP2C9_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith', 'CYP2C9_Substrate_CarbonMangels', 'CYP2D6_Substrate_CarbonMangels', 'CYP3A4_Substrate_CarbonMangels', 'hERG', 'AMES', 'DILI']\n",
    "\n",
    "for dataset in ['CYP2D6_Substrate_CarbonMangels', 'HIA_Hou']:\n",
    "\n",
    "    xgbScoring = None\n",
    "    gcnScoring = None\n",
    "\n",
    "    if(dataset in ['CYP2C9_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith', 'CYP2C9_Substrate_CarbonMangels','CYP2D6_Substrate_CarbonMangels']):\n",
    "           xgbScoring = praucMetric\n",
    "           gcnScoring = praucMetricWrapped\n",
    "           print(\"prauc\")\n",
    "    else:\n",
    "           xgbScoring = deepchem.deepchem.metrics.roc_auc_score\n",
    "           gcnScoring = rocAucMetric\n",
    "           print(\"rocauc\")\n",
    "\n",
    "    benchmark = group.get(dataset)\n",
    "    name = benchmark[\"name\"]\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = 1)  \n",
    "    results = {}\n",
    "\n",
    "    train_valMol = train_val.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "    testMol = test.iloc[:,1].map(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost (estate)\n",
    "    trainValEstateFeat = np.stack(np.array(train_valMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "    testEstateFeat = np.stack(np.array(testMol.map(lambda x: Fingerprinter.FingerprintMol(x)[1])))\n",
    "\n",
    "    #featurize training, valid, and test data for xgboost (ecfp)\n",
    "    trainValEcfpFeat = ecfpFeat.featurize(train_val.iloc[:,1].to_list())\n",
    "    testEcfpFeat = ecfpFeat.featurize(test.iloc[:,1].to_list())\n",
    "\n",
    "    #featurize training, valid, and test data for the GCN\n",
    "    trainGcnFeat = convMolFeat.featurize(train.iloc[:,1].to_list())\n",
    "    validGcnFeat = convMolFeat.featurize(valid.iloc[:,1].to_list())\n",
    "    testGcnFeat = convMolFeat.featurize(test.iloc[:,1].to_list())\n",
    "\n",
    "    #convert training and validation data into a deepchem dataset for the gcn\n",
    "    gcn_train_data = deepchem.deepchem.data.NumpyDataset(X=trainGcnFeat, y=np.array(train.iloc[:,2]), ids=np.array(train.iloc[:,1].to_list()))\n",
    "    gcn_valid_data = deepchem.deepchem.data.NumpyDataset(X=validGcnFeat, y=np.array(valid.iloc[:,2]), ids=np.array(valid.iloc[:,1].to_list()))\n",
    "\n",
    "    #tune estate classifier\n",
    "    clfEstate = GridSearchCV(estimator=xgb_reg_estate, param_grid=params, scoring=xgbScoring, cv=10)\n",
    "    clfEstate.fit(trainValEstateFeat, train_val.iloc[:,2])\n",
    "    results[\"estate\"] = clfEstate.best_params_\n",
    "\n",
    "    #tune ecfp classifier\n",
    "    clfEcfp = GridSearchCV(estimator=xgb_reg_ecfp, param_grid=params, scoring=xgbScoring, cv=10)\n",
    "    clfEcfp.fit(trainValEcfpFeat, train_val.iloc[:,2])\n",
    "    results[\"ecfp\"] = clfEcfp.best_params_\n",
    "\n",
    "    def model_builder(**model_params):\n",
    "       return deepchem.deepchem.models.GraphConvModel(n_tasks=1, mode=\"classification\", graph_conv_layers=[128, 128, 64])\n",
    "\n",
    "    optimizer = deepchem.deepchem.hyper.GaussianProcessHyperparamOpt(model_builder)\n",
    "\n",
    "    params_dict = {\"dropout\": .01,} #\"dense_layer_size\": 200}\n",
    "\n",
    "    best_model, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, gcn_train_data, gcn_valid_data, gcnScoring, search_range=2)\n",
    "    results[\"gcn\"] = best_hyperparams\n",
    "\n",
    "    print(name)\n",
    "    print(results)\n",
    "\n",
    "    predictions_list = []\n",
    "\n",
    "    for seed in [1, 2, 3, 4, 5]:\n",
    "\n",
    "      predictions = {}\n",
    "\n",
    "      trainBench, validBench = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "      ecfp_benchmark_reg = xgboost.XGBClassifier(max_depth=results[\"ecfp\"][\"max_depth\"])\n",
    "      estate_benchmark_reg = xgboost.XGBClassifier(max_depth=results[\"estate\"][\"max_depth\"])\n",
    "\n",
    "      #colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=5000\n",
    "\n",
    "      trainGcnFeatBench = convMolFeat.featurize(trainBench.iloc[:,1].to_list())\n",
    "      validGcnFeatBench = convMolFeat.featurize(validBench.iloc[:,1].to_list())\n",
    "\n",
    "      gcn_bench_train_data = deepchem.deepchem.data.NumpyDataset(X=trainGcnFeatBench, y=np.array(trainBench.iloc[:,2]), ids=np.array(trainBench.iloc[:,1].to_list()))\n",
    "      gcn_bench_valid_data = deepchem.deepchem.data.NumpyDataset(X=validGcnFeatBench, y=np.array(validBench.iloc[:,2]), ids=np.array(validBench.iloc[:,1].to_list()))\n",
    "\n",
    "      reg = deepchem.deepchem.models.GraphConvModel(\n",
    "         n_tasks=1, \n",
    "         dropout=results[\"gcn\"][\"dropout\"],\n",
    "         dense_layer_size=400,#results[\"gcn\"][\"dense_layer_size\"],\n",
    "         graph_conv_layers=[128, 128, 64],\n",
    "         mode=\"classification\",)\n",
    "      callback = deepchem.deepchem.models.ValidationCallback(gcn_bench_valid_data, 1000, gcnScoring)\n",
    "      reg.fit(gcn_bench_train_data, nb_epoch=100, callbacks=callback)\n",
    "\n",
    "      #I don't think eval_metric does anything if there's no eval_set specified,\n",
    "      #but if there is one, I think you're supposed to pass a string like \"mae\"\n",
    "      estate_benchmark_reg.fit(X=trainValEstateFeat, y=train_val.iloc[:,2], eval_metric=xgbScoring, verbose=True)\n",
    "      ecfp_benchmark_reg.fit(X=trainValEcfpFeat, y=train_val.iloc[:,2], eval_metric=xgbScoring)\n",
    "      \n",
    "      pred_estate = estate_benchmark_reg.predict(X=testEstateFeat)\n",
    "      pred_ecfp = ecfp_benchmark_reg.predict(X=testEcfpFeat)\n",
    "\n",
    "      gcn_pred_raw = reg.predict_on_batch(X=np.array(testGcnFeat))\n",
    "      gcn_pred = []\n",
    "      for prediction in gcn_pred_raw:\n",
    "       gcn_pred.append(prediction[0][1])\n",
    "\n",
    "      print(gcn_pred[0:5])\n",
    "      print(pred_ecfp[0:5])\n",
    "      print(pred_estate[0:5])\n",
    "\n",
    "      y_pred_test = np.round(np.mean([ pred_estate, pred_ecfp, gcn_pred ], axis=0))\n",
    "\n",
    "      print(\"predictions for run #\")\n",
    "      print(seed)\n",
    "      print(y_pred_test[0:5])\n",
    "\n",
    "      predictions[name] = y_pred_test\n",
    "      predictions_list.append(predictions)\n",
    "\n",
    "    print(predictions_list)\n",
    "    print(group.evaluate_many(predictions_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hia_hou': [0.818, 0.021]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.evaluate_many(predictions_list[5:11])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d9ef161e060c37aa994177a4d833cab797e22621213b4f88b9fe284585c74c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deepchem-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
